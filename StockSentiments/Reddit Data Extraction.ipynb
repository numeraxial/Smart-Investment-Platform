{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7b4c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "# Twitter API\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "# Reddit API\n",
    "import praw\n",
    "# Text Analyzing\n",
    "from textblob import TextBlob\n",
    "# MongoDB\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "# stockName = \"AAPL\"\n",
    "stockName = sys.argv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ea0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SentimentAnalyzer(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console\n",
    "        consumer_key = \"9LanGta2OOzJBITyWRacIyxUR\"\n",
    "        consumer_secret = \"mAfvIGHwHblw0bMJfszyn2voADCUWLEAT1ezbgPPiZb1geHi8X\"\n",
    "        access_token = \"1428093851726663696-55Xp7zjUQknkuPRDzCObGCcIQuxmOh\"\n",
    "        access_token_secret = \"1jxsg4RdkszPMURIRi78aNm2hoHwMzz4VrBU69gmOV0gm\"\n",
    "\n",
    "        # keys and id from the Reddit Dev Console\n",
    "        \n",
    "\n",
    "        # connection to MongoDB\n",
    "        self.client = MongoClient('localhost', 27017)\n",
    "        self.db = self.client.numeraxial\n",
    "        self.collections = self.db.list_collection_names()\n",
    "        self.collection_name = self.db.sentiments\n",
    "        \n",
    "        # attempt authentication\n",
    "        try:\n",
    "\n",
    "            # TWITTER\n",
    "            # create OAuthHandler object\n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "            self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "            self.api = tweepy.API(self.auth)\n",
    "\n",
    "            # REDDIT\n",
    "            self.reddit = praw.Reddit(client_id = \"18uKEpIOKA-Q9egZ9cqluA\",\n",
    "                                    client_secret = \"Wsg75jOgphdmZ64JZcbKWqbzoXemQg\",\n",
    "                                    user_agent = \"Scraping\")\n",
    "            self.all = self.reddit.subreddit(\"WallStreetBets+stocks+investing+pennystocks+robinhood\")\n",
    "\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        # set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self, query, count=10):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    "\n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = self.api.search(q=query, count=count)\n",
    "\n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = {}\n",
    "\n",
    "                # saving text of tweet\n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                # saving sentiment of tweet\n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(\n",
    "                    tweet.text)\n",
    "\n",
    "                # appending parsed tweet to tweets list\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    "\n",
    "            ptweets = [\n",
    "                tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "            ntweets = [\n",
    "                tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "            percentagePTweets = 100*len(ptweets)/len(tweets)\n",
    "            percentageNTweets = 100*len(ntweets)/len(tweets)\n",
    "            percentageNUTweets = 100 * \\\n",
    "                (len(tweets) - (len(ntweets)+len(ptweets)))/len(tweets)\n",
    "            \n",
    "            return {\n",
    "                'Positive': percentagePTweets,\n",
    "                'Negative': percentageNTweets,\n",
    "                'Neutral': percentageNUTweets\n",
    "            }\n",
    "\n",
    "        except tweepy.TweepError as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))\n",
    "\n",
    "    def get_reddit(self, query):\n",
    "        sentiment_analysis = {'positive': 0,\n",
    "                              'negative': 0,\n",
    "                              'neutral': 0\n",
    "                              }\n",
    "\n",
    "        for submission in self.all.search(query,\"Stock\", limit=None):\n",
    "            analysis = TextBlob(submission.title)\n",
    "            if analysis.sentiment.polarity > 0:\n",
    "                sentiment_analysis['positive'] += 1\n",
    "            elif analysis.sentiment.polarity == 0:\n",
    "                sentiment_analysis['neutral'] += 1\n",
    "            else:\n",
    "                sentiment_analysis['negative'] += 1\n",
    "\n",
    "        total = sum(sentiment_analysis.values())/100\n",
    "        percentagePReddit = float('{:.2f}'.format(\n",
    "            sentiment_analysis['positive']/total))\n",
    "        percentageNReddit = float('{:.2f}'.format(\n",
    "            sentiment_analysis['negative']/total))\n",
    "        percentageNUReddit = float('{:.2f}'.format(\n",
    "            sentiment_analysis['neutral']/total))\n",
    "\n",
    "        return {\n",
    "            'Positive': percentagePReddit,\n",
    "            'Negative': percentageNReddit,\n",
    "            'Neutral': percentageNUReddit\n",
    "        }\n",
    "\n",
    "    def get_sentiment(self, query, count=10):\n",
    "        twitter_result = self.get_tweets(query, count)\n",
    "        reddit_result = self.get_reddit(query)\n",
    "        \n",
    "        # Hash result\n",
    "        twitterPositive = twitter_result['Positive']\n",
    "        entry = {\n",
    "            'Stock': query,\n",
    "            'Sentiment': {\n",
    "                'Twitter': {\n",
    "                    'Positive': twitter_result['Positive'],\n",
    "                    'Negative': twitter_result['Negative'],\n",
    "                    'Neutral': twitter_result['Neutral'],\n",
    "                },\n",
    "                'Reddit': {\n",
    "                    'Positive': reddit_result['Positive'],\n",
    "                    'Negative': reddit_result['Negative'],\n",
    "                    'Neutral': reddit_result['Neutral'],\n",
    "                }\n",
    "            }\n",
    "\n",
    "        }\n",
    "        self.collection_name.update_one(\n",
    "            {'Stock': query}, {\"$set\": entry}, True)\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # creating object of TwitterClient Class\n",
    "    api = SentimentAnalyzer()\n",
    "    # calling function to get tweets\n",
    "    api.get_sentiment(query=\"Macy's\", count=200)\n",
    "\n",
    "\n",
    "main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
